# Gemini CLI Code Review

- model: gemini-2.5-flash-lite
- generated_at: 2026-02-15T13:11:24.635Z
- files_sent: 26
- total_bytes_sent: 192090

Este é um code review do projeto **whatsapp-ml-bot**. O projeto demonstra uma arquitetura sólida para um MVP, com bom uso de padrões assíncronos e separação de responsabilidades.

### Resumo Executivo
- **Arquitetura:** Separação clara entre bot, serviços (ML, OpenAI) e persistência.
- **Robustez:** Implementação de retentativas para erros específicos do ML (PolicyAgent) e limpeza automática de dados.
- **UX:** Fluxo de "sessão" bem definido para agrupar fotos e interações do usuário.
- **Risco Principal:** Uso de biblioteca não-oficial do WhatsApp (Baileys), sujeita a banimentos por spam ou violação de termos.
- **Persistência:** O uso de um único arquivo JSON para banco de dados é prático para escala pequena, mas um gargalo potencial de performance e concorrência.
- **IA:** Uso eficiente de *Structured Outputs* da OpenAI para garantir consistência no processamento de imagens.

---

### Análise por Severidade

#### [ALTO] Risco de Banimento e Falta de Rate Limiting
**Arquivo:** `src/bot/WhatsAppMlBot.ts`
O bot responde e baixa mídias instantaneamente. O WhatsApp detecta padrões automatizados de alta velocidade. 
- **Problema:** O método `handleImage` e `reply` não possuem atrasos "humanos" simulados.
- **Impacto:** Bloqueio permanente do número do WhatsApp associado ao bot.
- **Melhoria:** Implementar pequenos `delay` aleatórios (2-5s) antes de responder e limitar o número de sessões simultâneas por usuário.

#### [ALTO] Escalabilidade do Banco de Dados JSON
**Arquivo:** `src/storage/store.ts`
- **Problema:** O método `read()` lê e faz o parse do arquivo inteiro em cada operação. O `update()` reescreve o arquivo todo.
- **Impacto:** À medida que o número de sessões aumenta (mesmo com cleanup), o I/O e o parse do JSON bloquearão o Event Loop do Node.js, degradando a performance do bot.
- **Melhoria:** Migrar para um banco de dados KV embarcado (ex: **SQLite** via `better-sqlite3` ou **LevelDB**). Se mantiver JSON, considere separar tokens de sessões.

#### [MÉDIO] Consumo de Memória no Processamento de Imagens
**Arquivo:** `src/bot/WhatsAppMlBot.ts` (linha 225)
- **Problema:** O bot baixa o buffer da imagem (`downloadMediaMessage`) e o mantém em memória antes de salvar no disco.
- **Impacto:** Se vários usuários enviarem múltiplas fotos de alta resolução simultaneamente, o processo pode sofrer *Out of Memory* (OOM).
- **Melhoria:** Utilizar *streams* para salvar o arquivo diretamente no disco durante o download da mídia do Baileys, em vez de carregar o `Buffer` completo.

#### [MÉDIO] Fragilidade na Captura de Atributos Obrigatórios
**Arquivo:** `src/bot/WhatsAppMlBot.ts` (linha 578)
O bot tenta extrair IDs de atributos de erros do ML usando Regex em mensagens de erro.
- **Problema:** Mensagens de erro de APIs podem mudar sem aviso prévio. 
- **Impacto:** O bot pode não conseguir guiar o usuário corretamente sobre o que falta no anúncio.
- **Melhoria:** Priorizar sempre a resposta estruturada de `cause_details` da API do Mercado Livre em vez de fazer o parse da string `message`.

#### [BAIXO] Tipagem Fraca em Mensagens (Baileys)
**Arquivo:** `src/bot/WhatsAppMlBot.ts` (linha 25)
- **Problema:** O uso de `type WAMessage = any` anula os benefícios do TypeScript no componente mais crítico do sistema.
- **Impacto:** Bugs de *null pointer* difíceis de rastrear ao acessar propriedades de mensagens.
- **Melhoria:** Importar e utilizar as interfaces nativas do Baileys (ex: `proto.IWebMessageInfo`).

---

### Observações Específicas

#### WhatsApp (Baileys)
A estratégia de `WA_ALLOWED_GROUP_IDS` no `config.ts` é excelente para segurança, evitando que o bot seja usado fora do escopo planejado. Recomenda-se adicionar um `presence subscribe` para simular "digitando..." enquanto a OpenAI processa a imagem, melhorando a percepção de UX.

#### OpenAI Vision
O uso de `gpt-4o-mini` (`src/config.ts`) é uma escolha custo-benefício inteligente. No entanto, o `analyzeProduct` envia até 8 imagens em alta definição. 
**Sugestão:** Redimensionar as imagens localmente (ex: usando `sharp`) para no máximo 768px ou 1024px antes do upload para a OpenAI, economizando tokens de input e largura de banda.

#### Mercado Livre (OAuth & Status Paused)
O fluxo de `ML_DRY_RUN` é muito útil para testes. No entanto, o `ML_REFRESH_TOKEN` é gerenciado manualmente no `.env`.
**Melhoria:** Como o bot já tem um `JsonDbStore`, o script `ml-oauth.ts` poderia salvar o token diretamente no `db.json` para que o bot o utilize no próximo ciclo, evitando a edição manual do `.env` sempre que o token expirar (tokens de aplicativos não-oficiais do ML podem expirar em 6 meses, mas o refresh token pode mudar).

---

### Sugestões de Testes Automatizados Essenciais

1. **Testes de Integração de Fluxo (Mockado):**
   - Simular o envio de 3 fotos dentro da janela de tempo e verificar se apenas uma chamada à OpenAI é disparada.
   - Simular o comando `cancelar` durante a fase de `analyzing` para garantir que o resultado da IA seja descartado (evitar *race conditions*).

2. **Testes de Parser de Atributos:**
   - Testar `parseUserAttributeValue` com entradas variadas: `cor=Azul`, `cor= @123`, `cor=name:Azul`.

3. **Teste de Resiliência de Erro:**
   - Mockar a API do Mercado Livre retornando um erro 403 (PolicyAgent) e validar se o `MercadoLivreClient` tenta a segunda chamada com `auth: true`.

4. **Teste de Limpeza (Cleanup):**
   - Inserir sessões antigas no banco mock e validar se `runCleanupOnce` remove os arquivos físicos de mídia correspondentes.
